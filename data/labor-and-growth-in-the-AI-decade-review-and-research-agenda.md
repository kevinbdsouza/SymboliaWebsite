
# Navigating Labor and Growth in the AI Future: A Review and Research Agenda
Artificial Intelligence (AI) stands poised to reshape economies and societies profoundly over the coming decades, yet the nature and magnitude of its impact remain subjects of intense debate and considerable uncertainty. We review the diverse spectrum of projections concerning AI's consequences for labor markets, productivity, wages, economic growth, and human flourishing, and synthesize contrasting viewpoints, ranging from utopian visions of unprecedented prosperity to dystopian scenarios of widespread disruption and inequality. We scrutinize the methodologies underpinning these forecasts, and identify limitations in predicting technological breakthroughs, modeling complex task dynamics and real-world frictions, and capturing crucial feedback loops between technology, policy, and society. Our analysis advocates for a more integrated, granular, and context-aware research agenda focusing on skill dynamics, institutional influences, and human-AI collaboration. Ultimately, we argue that navigating the AI future requires interdisciplinary research, proactive policy interventions, and a commitment to responsible innovation centered on human values to ensure that AI's potential benefits humanity broadly.

## The AI Paradox: Unprecedented Potential Amidst Deep Uncertainty
The contemporary wave of AI represents more than just an incremental technological advancement; it carries the hallmarks of a potential general-purpose technology, characterized by its pervasiveness across economic sectors, potential for continuous improvement, and capacity to spawn complementary innovations [[CBO](https://www.cbo.gov/publication/61147), [Aghion, P. et al. 2017](https://www.nber.org/system/files/working_papers/w23928/w23928.pdf), [Brynjolfsson, E. et al. 2019](https://www.nber.org/system/files/working_papers/w24001/w24001.pdf)]. Unlike previous technological shifts, the accelerating pace of AI development suggests the potential for transformations that are not only deep but also rapid [[McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier)], challenging established economic structures and social norms within the coming decades. 

This potential precipitates a central tension that dominates discourse and policy debates. On one hand, AI is heralded as a catalyst for unprecedented productivity growth, capable of augmenting human capabilities, automating tedious tasks, accelerating scientific discovery, and ultimately fostering widespread economic prosperity and solutions to global challenges [[Brynjolfsson, E. et al. 2014](https://wwnorton.com/books/the-second-machine-age/), [Agrawal, A. et al. 2018](https://www.predictionmachines.ai/)]. On the other hand, significant concerns exist regarding AI's potential to act as a powerful substitute for human labor across a vast array of cognitive and manual domains, leading to substantial job displacement, exacerbating wage inequality, concentrating market power, and potentially undermining social cohesion and individual autonomy [[Acemoglu, D. et al. 2019](https://www.aeaweb.org/articles?id=10.1257/jep.33.2.3), [Korinek, A. et al. 2021](https://www.nber.org/papers/w28453), [Acemoglu, D. et al. 2023](https://shapingwork.mit.edu/power-and-progress/)].

Adding to this tension, there exists disagreement and uncertainty regarding the magnitude, nature, and timing of its actual impact. Enthusiastic projections of AI-driven prosperity [[AEA](https://www.aeaweb.org/conference/2020/preliminary/paper/Tz2HdRna)] clash with the persistent reality of sluggish aggregate productivity growth observed across many developed economies for over a decade [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)]. This disconnect highlights the complexity of translating technological possibility into widespread economic benefit. The relationship between AI and its economic consequences, especially for labor, remains surprisingly understudied, characterized by divergent theoretical models and empirical forecasts. Recent works by  [Korinek & Suh 2024](https://www.nber.org/papers/w32255), [Acemoglu, D. 2025](https://economics.mit.edu/sites/default/files/2024-04/The%20Simple%20Macroeconomics%20of%20AI.pdf), and [Epoch AI's GATE, 2025](https://arxiv.org/abs/2503.04941), while offering valuable insights, exemplify this divergence in forecasting AI's real-world implications.

We navigate this uncertain landscape and provide a synthesis of the potential impacts of AI over the coming decades, focusing on four interconnected domains:

1. **Economic Productivity**: Assessing AI's potential to drive aggregate economic growth through increased efficiency at the firm level, innovation, and the development of new goods and services.
2. **Labor Markets**: Examining effects on employment levels (job creation vs. destruction), shifts in skill demand, the changing composition of tasks within occupations, and workforce transitions.
3. **Wages**: Analyzing potential impacts on overall wage levels, the distribution of wages across different skill and income groups, and the trajectory of income inequality.
4. **Human Flourishing**: Moving beyond purely economic indicators to consider broader dimensions of well-being, including job quality, worker autonomy, and social cohesion.

Our central argument is that a comprehensive understanding requires grappling with the full spectrum of potential outcomes, critically evaluating the tools used for prediction, and broadening the analytical lens to encompass the multifaceted nature of human well-being in an increasingly AI-mediated world. 

This analysis is structured as follows. In section 1, we review the wide range of projections concerning AI's impact on productivity, labor markets, and wages, highlighting the optimistic and pessimistic viewpoints present in the literature. In section 2, we study the modeling approaches used to generate these forecasts, examining specific models and discussing recurring methodological limitations. In section 3, we expand the analysis to consider the implications of AI for human flourishing, exploring potential effects on work quality, social dynamics, and individual well-being. In section 4, we discuss the path forward, outlining key research priorities needed to address the identified knowledge gaps, drawing lessons from historical technological transitions, and summarizing relevant policy discussions. Finally, we offer concluding remarks, synthesizing the analysis and emphasizing the need to make progress on the research agenda discussed. 

## The Spectrum of Expectations: AI Futures from Utopia to Dystopia
Forecasts regarding AI's long-term socio-economic impact diverge dramatically, painting pictures that range from techno-optimistic utopias to deeply pessimistic dystopias. Understanding this spectrum is crucial, as these narratives shape public perception, investment decisions, and policy priorities.

### Optimistic Visions
Proponents of optimistic scenarios often emphasize AI's potential as a powerful complement to human labor. In this view, AI systems augment human capabilities, handle routine cognitive and manual tasks, and free up human workers to focus on activities requiring creativity, critical thinking, empathy, and complex problem-solving [[Brynjolfsson, E. et al. 2014](https://wwnorton.com/books/the-second-machine-age/)]. This augmentation is predicted to lead to substantial productivity gains across various sectors. Some forecasts envision AI driving a new era of economic abundance, potentially leading to significantly reduced working hours without a loss in living standards, and enabling society to tackle previously intractable problems like climate change, disease, and resource scarcity [[Agrawal, A. et al. 2018](https://www.predictionmachines.ai/)]. New jobs and tasks, often centered around developing, managing, and collaborating with AI systems, are expected to emerge, offsetting potential displacement effects. This perspective often draws parallels with historical technological revolutions where initial disruption eventually led to higher overall prosperity and new forms of employment [[Brynjolfsson, E. et al. 2019](https://www.nber.org/system/files/working_papers/w24001/w24001.pdf)].

### Pessimistic Visions
Conversely, pessimistic scenarios highlight AI's potential as a widespread substitute for human labor. As AI capabilities advance, particularly towards Artificial General Intelligence (AGI) or highly capable narrow AI systems, they could automate not only routine tasks but also a significant portion of complex cognitive and creative work currently performed by humans [[Acemoglu, D. et al. 2019](https://www.aeaweb.org/articles?id=10.1257/jep.33.2.3), [Acemoglu, D. et al. 2023](https://shapingwork.mit.edu/power-and-progress/)]. This perspective warns of the possibility of mass unemployment or chronic underemployment, as the pace of automation outstrips the creation of new tasks or the ability of the workforce to adapt. Even if overall wealth increases, the distribution of gains is a major concern. Pessimists project a dramatic rise in inequality, with the owners of AI capital capturing an ever-larger share of national income, while wages for most workers stagnate or decline [[Korinek, A. et al. 2021](https://www.nber.org/papers/w28453)]. This could lead to an erosion of the middle class, increased social stratification, and potential political instability. Concerns also extend to non-economic domains, including the potential for algorithmic bias to perpetuate discrimination, the erosion of privacy through sophisticated surveillance, the manipulation of behavior through personalized algorithms, and a general loss of human autonomy and purpose in an increasingly automated world [[Acemoglu, D. et al. 2023](https://shapingwork.mit.edu/power-and-progress/)].

### Underlying Drivers of Divergence
The chasm between these optimistic and pessimistic outlooks stems from fundamental disagreements about several key factors. Assumptions regarding the nature and speed of future AI development are critical; forecasts differ based on whether AI remains narrow or progresses towards AGI, and how quickly transformative capabilities emerge. Equally important are assumptions about the elasticity of substitution between AI and human labor across different tasks, i.e., how easily can AI replace human workers, and conversely, how strongly does it complement them? [[Acemoglu, D. et al. 2019](https://www.aeaweb.org/articles?id=10.1257/jep.33.2.3)]. Differing views on the elasticity of labor demand in new, AI-enabled sectors and the capacity for new task creation also drive divergent predictions. Finally, implicit or explicit assumptions about the effectiveness and nature of policy responses play a crucial role; optimists may assume proactive measures to manage transitions and redistribute gains, while pessimists may anticipate policy gridlock or capture by vested interests [[Korinek, A. et al. 2021](https://www.nber.org/papers/w28453)].

It is important to recognize that this divergence often reflects more than just different parameter choices within quantitative models. It frequently stems from fundamentally different mental models or worldviews regarding how technological innovation interacts with complex socio-economic systems. Optimistic narratives may implicitly rely on assumptions of market efficiency, smooth adjustments, and the capacity for effective redistribution, perhaps underestimating frictions, power imbalances, and path dependencies inherent in real-world transitions. Pessimistic narratives, conversely, tend to emphasize these frictions, the potential for winner-take-all dynamics, and the historical tendency for technological gains to be unevenly distributed, at least initially. Understanding these underlying conceptual frameworks is as vital as scrutinizing quantitative parameters when evaluating the credibility and implications of different forecasts.

The very language used to frame the discussion, predominantly focusing on "automation" versus "augmentation", carries significant weight. This framing can influence public attitudes, shape research directions, and steer policy orientations. A dominant narrative emphasizing job substitution might foster protectionist sentiments or prioritize passive income schemes, potentially leading to underinvestment in crucial areas like workforce retraining, lifelong learning, or research into human-AI collaboration. Conversely, a narrative centered on augmentation could stimulate proactive policies aimed at developing complementary skills and fostering environments where humans and AI work synergistically. Thus, the framing itself can act as a partially self-fulfilling prophecy, influencing the trajectory of AI deployment and its ultimate societal consequences.

## Divergent Futures: Projections of AI's Economic Impact
Forecasts regarding AI's economic impact over the coming years and decades span a remarkably wide spectrum, reflecting deep uncertainties about the technology's trajectory and its interaction with complex socio-economic systems.

### Productivity Growth: Explosion or Marginal?
A central debate revolves around AI's potential to break the trend of sluggish productivity growth observed in many advanced economies [[Aghion, P. et al. 2017](https://www.nber.org/system/files/working_papers/w23928/w23928.pdf)]. Many analyses project substantial productivity enhancements driven by AI. By automating tasks, optimizing processes, improving prediction, and accelerating innovation, AI could significantly boost output per worker across numerous industries [[CBO](https://www.cbo.gov/publication/61147), [Agrawal, A. et al. 2018](https://www.predictionmachines.ai/)]. Generative AI, in particular, is highlighted for its potential economic value. McKinsey estimates it could add the equivalent of $2.6 trillion to $4.4 trillion annually across analyzed use cases, a figure comparable to the entire GDP of the UK in 2021, potentially doubling if embedded within existing software [[McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier)]. Including broader productivity effects across knowledge work, the total estimated annual benefit rises to $6.1 trillion to $7.9 trillion [[McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier)]. This optimism extends to the very process of innovation, with predictions that AI could compress decades of scientific progress into significantly shorter timeframes, accelerating breakthroughs in critical areas.

Micro-level evidence lends some support to these optimistic projections. Studies indicate that firms implementing non-generative AI have seen productivity gains comparable to previous digital technologies (up to 10%), while experiments with generative AI assisting workers in tasks like writing, programming, or customer service show substantially larger performance benefits (ranging from 15% to 56%), particularly for less experienced workers [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)]. Other research examining the adoption of AI technologies by firms sometimes finds positive correlations with productivity metrics, suggesting that early adopters are reaping tangible benefits [[Babina, T. et al. 2024](https://www.nber.org/papers/w31325)]. These studies often indicate that realizing these gains depends on factors beyond the technology itself, such as the availability of large datasets, investments in complementary digital infrastructure and organizational changes, and management quality capable of effectively integrating AI into workflows [[Babina, T. et al. 2024](https://www.nber.org/papers/w31325)]. Based on such potential, some analysts forecast that AI could contribute an additional 1 to 1.5 percentage points to annual economic growth rates over the next 10-20 years [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)]. When combined with other automation technologies, the potential annual boost to productivity growth could range from 0.2 to 3.3 percentage points, depending on adoption rates and worker redeployment [[WEF, 2023](https://www.weforum.org/stories/2023/07/generative-ai-could-add-trillions-to-global-economy/)].

Despite these promising indicators, a counterargument arises from the persistent "productivity paradox" - the observation of slow aggregate productivity growth despite rapid technological advancements [[Brynjolfsson, E. et al. 2019](https://www.nber.org/system/files/working_papers/w24001/w24001.pdf)]. Labor productivity growth in OECD economies decelerated significantly in the mid-2000s, well before the recent AI surge, and has remained low since [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)]. Aggregate statistics, admittedly backward-looking, show little evidence thus far that AI has reversed this trend, even as firm-level studies report gains [[AEA](https://www.aeaweb.org/conference/2020/preliminary/paper/Tz2HdRna)]. Research examining the period up to the late 2010s found no discernible relationship between AI exposure and aggregate employment or wage growth, suggesting that while AI was substituting for tasks, its overall labor market consequences were not yet detectable at a macro level [[Acemoglu, D. et al. 2024](https://shapingwork.mit.edu/wp-content/uploads/2023/10/Paper_Artificial-Intelligence-and-Jobs-Evidence-from-Online-Vacancies.pdf)]. Historical context suggests that implementation lags are common with transformative technologies, as complementary investments, organizational restructuring, and skill development take time [[Brynjolfsson, E. et al. 2019](https://www.nber.org/system/files/working_papers/w24001/w24001.pdf)]. Structural economic factors, such as Baumol's cost disease, might limit aggregate growth even if AI boosts productivity in specific sectors. If AI primarily enhances productivity in activities with saturating demand or if sectors less amenable to AI (like labor-intensive personal services) continue to absorb a large share of employment, the overall growth impact could be muted [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)]. 

The divergence between observed firm-level productivity gains [[AEA](https://www.aeaweb.org/conference/2020/preliminary/paper/Tz2HdRna)] and lagging aggregate statistics [[Brynjolfsson, E. et al. 2019](https://www.nber.org/system/files/working_papers/w24001/w24001.pdf)] points towards diffusion barriers, the necessity of substantial complementary investments, or the possibility that current AI applications, while beneficial at the micro level, are either too narrow in scope or primarily displace existing activities without generating substantial net value at the macroeconomic level yet. Measurement issues may play a role, as traditional statistics might not fully capture quality improvements or the value generated by intangible AI-driven services. The benefits might currently be concentrated among a small number of frontier firms, requiring broader adoption before aggregate effects become visible. Some even argue that AI talent and investment might be misallocated, with low focus on applications with broader productivity-enhancing potential across fundamental sectors like manufacturing, healthcare, or education. It could also be the case that with the AI breakthroughs of the past few years, aggregate statistics may look very different in the late 2020’s and we just haven’t seen enough data yet. 

The pattern of AI adoption itself may influence aggregate productivity outcomes in complex ways. If, as some evidence suggests [[Babina, T. et al. 2024](https://www.nber.org/papers/w31325)], early and significant productivity gains from AI accrue primarily to large, technologically advanced "frontier" firms that possess the necessary data, capital, and specialized expertise, this could widen the performance gap between these leaders and smaller or slower-adopting "laggard" firms. Such a dynamic could lead to increased market concentration, as frontier firms leverage their AI advantage to gain market share. While this boosts productivity at the firm level for adopters, it might paradoxically slow down aggregate productivity growth if it stifles competition, hinders the diffusion of innovations to the rest of the economy, and leads to resource misallocation towards dominant firms. This micro-macro disconnect represents a fundamental challenge for economic modeling: accurately scaling observations from individual firms or workers to economy-wide predictions requires accounting for factors beyond the technology itself, such as market structure, competitive dynamics, regulatory environments, and the pace of organizational adaptation, elements often simplified or omitted in current models.

### Labor Market Dynamics: Job Creation, Destruction, and Transformation
Perhaps the most contentious area of AI's impact concerns the future of work and employment levels. Fears of widespread technological unemployment are prominent in many forecasts. Many studies employ task-based approaches, analyzing the constituent tasks of occupations to estimate their susceptibility to automation by current and anticipated AI capabilities [[Acemoglu, D. et al. 2019](https://www.aeaweb.org/articles?id=10.1257/jep.33.2.3), [Acemoglu, D. 2025](https://economics.mit.edu/sites/default/files/2024-04/The%20Simple%20Macroeconomics%20of%20AI.pdf)]. These analyses often suggest that a significant percentage of existing tasks, and by extension jobs, have high theoretical exposure to automation. Recent empirical work attempts to move beyond theoretical exposure by examining the actual labor market consequences associated with automation risk or AI adoption. For instance, studies analyzing the impact of automation risk exposure find correlations with outcomes such as reduced employment growth, lower wage growth, or shifts in firm dynamics, potentially indicating that automation pressures are already manifesting in labor market data [[Acemoglu, D. et al. 2024](https://shapingwork.mit.edu/wp-content/uploads/2023/10/Paper_Artificial-Intelligence-and-Jobs-Evidence-from-Online-Vacancies.pdf)]. Such research often highlights differential impacts, suggesting that workers with certain skill sets, in specific industries, or employed by particular types of firms may be more vulnerable [[Acemoglu, D. et al. 2024](https://shapingwork.mit.edu/wp-content/uploads/2023/10/Paper_Artificial-Intelligence-and-Jobs-Evidence-from-Online-Vacancies.pdf)].

Estimates of the number of jobs potentially automated or displaced by AI vary dramatically but often paint a picture of significant disruption. Figures range from nearly 40% of global employment being exposed to AI [[IMF](https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity)] to specific predictions like 300 million full-time jobs globally [[Howarth, J. 2025](https://explodingtopics.com/blog/ai-replacing-jobs)], potentially rising to 800 million worldwide by 2030 [[SEO](https://seo.ai/blog/ai-replacing-jobs-statistics)]. Other studies suggest 85 million jobs could be displaced globally by 2025 [[Forbes](https://www.forbes.com/councils/forbestechcouncil/2024/03/12/the-future-of-work-embracing-ais-job-creation-potential/)]. Certain sectors and roles are deemed particularly vulnerable, including manufacturing (with a forecast of 2 million workers replaced by automation, including AI-powered tools, by 2025 [[Howarth, J. 2025](https://explodingtopics.com/blog/ai-replacing-jobs)]), data entry, administrative support, and accounting [[Howarth, J. 2025](https://explodingtopics.com/blog/ai-replacing-jobs)]. The advent of generative AI has heightened these concerns, as its proficiency with natural language understanding expands the potential scope of automation into knowledge work. McKinsey estimates that current technologies, including generative AI, could automate activities absorbing 60-70% of employees' time [[McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier)], an increase from previous estimates of 50%. Another McKinsey analysis projects generative AI could automate 29.5% of hours worked in the US economy by 2030 [[Rege, M. et al. 2024](https://news.stthomas.edu/generative-ais-real-world-impact-on-job-markets/)]. Research suggests 80% of the US workforce could see at least 10% of their tasks impacted by large language models [[Howarth, J. 2025](https://explodingtopics.com/blog/ai-replacing-jobs)]. Evidence of actual replacement is emerging, with surveys indicating some US companies have replaced workers with AI tools [[Howarth, J. 2025](https://explodingtopics.com/blog/ai-replacing-jobs)], specific instances of AI-related job cuts being reported [[Howarth, J. 2025](https://explodingtopics.com/blog/ai-replacing-jobs)], and firms like British Telecom announcing plans to replace staff with AI over the medium term [[SEO](https://seo.ai/blog/ai-replacing-jobs-statistics)].

Counterbalancing these concerns are arguments emphasizing AI's potential to create new jobs and augment human capabilities [[Brynjolfsson, E. et al. 2014](https://wwnorton.com/books/the-second-machine-age/)]. Historical precedents are often invoked, noting that previous technological revolutions ultimately created more jobs than they destroyed [[Forbes](https://www.forbes.com/councils/forbestechcouncil/2024/03/12/the-future-of-work-embracing-ais-job-creation-potential/)], and that computerization, while eliminating some roles, also led to job growth in others [[Halal, W. et al. 2016](https://jfsdigital.org/wp-content/uploads/2017/01/JFS212Final%EF%BC%88%E5%B7%B2%E6%8B%96%E7%A7%BB%EF%BC%89-6.pdf)]. The continued growth in truck driver employment despite years of autonomous vehicle development serves as a recent cautionary tale against premature predictions of displacement [[BLS](https://www.bls.gov/opub/mlr/2025/article/incorporating-ai-impacts-in-bls-employment-projections.htm)]. Proponents of this view highlight the emergence of entirely new roles centered around AI development, deployment, and management, such as AI specialists, data scientists, and machine learning engineers [[Forbes](https://www.forbes.com/councils/forbestechcouncil/2024/03/12/the-future-of-work-embracing-ais-job-creation-potential/)]. Forecasts suggest significant job creation potential, with the WEF projecting 97 million new roles emerging globally by 2025 alongside the 85 million displaced [[Forbes](https://www.forbes.com/councils/forbestechcouncil/2024/03/12/the-future-of-work-embracing-ais-job-creation-potential/)], and a later WEF report anticipating 170 million new roles by 2030 versus 92 million made redundant [[WEF](https://sustainabilitymag.com/articles/wef-report-the-impact-of-ai-driving-170m-new-jobs-by-2030)]. 

A significant body of work emphasizes AI's role in augmenting human workers rather than replacing them outright [[WEF, 2023](https://www.weforum.org/stories/2023/07/generative-ai-could-add-trillions-to-global-economy/)]. AI tools can enhance productivity, particularly for less experienced workers, enabling them to perform tasks previously requiring greater expertise [[WEF](https://sustainabilitymag.com/articles/wef-report-the-impact-of-ai-driving-170m-new-jobs-by-2030)]. The concept of "hybrid intelligence," combining the strengths of human cognition (insight, judgment, empathy) with AI's analytical power, points towards a future of collaboration [[Walther, C. 2025](https://knowledge.wharton.upenn.edu/article/why-hybrid-intelligence-is-the-future-of-human-ai-collaboration/)]. Real-world usage data from Anthropic's Claude model indicated that 57% of its use involved augmenting human capabilities (e.g., validation, learning, brainstorming) compared to 43% involving direct automation [30]. Even when tasks within an occupation are automated, this may lead to a transformation of the job role rather than its elimination [[BLS](https://www.bls.gov/opub/mlr/2025/article/incorporating-ai-impacts-in-bls-employment-projections.htm)]. McKinsey found fewer than 5% of occupations could be entirely automated with current technology, although a majority (60%) could see 30% or more of their constituent activities automated [[Halal, W. et al. 2016](https://jfsdigital.org/wp-content/uploads/2017/01/JFS212Final%EF%BC%88%E5%B7%B2%E6%8B%96%E7%A7%BB%EF%BC%89-6.pdf)]. Interestingly, establishment-level studies reveal a complex picture: firms with higher AI exposure tend to post more AI-related vacancies but also show lower hiring for non-AI positions, suggesting task substitution is occurring at the firm level [[Acemoglu, D. et al. 2024](https://shapingwork.mit.edu/wp-content/uploads/2023/10/Paper_Artificial-Intelligence-and-Jobs-Evidence-from-Online-Vacancies.pdf)]. However, these studies have not yet detected significant impacts on overall employment or wages at the broader industry or occupation level [[Acemoglu, D. et al. 2024](https://shapingwork.mit.edu/wp-content/uploads/2023/10/Paper_Artificial-Intelligence-and-Jobs-Evidence-from-Online-Vacancies.pdf)]. Conversely, other research links AI-related innovations within firms to faster overall employment growth [[AEA](https://www.aeaweb.org/conference/2020/preliminary/paper/Tz2HdRna)]. Overall, the critical question is whether the pace of augmentation and new task creation can keep pace with the rate of automation, and whether the workforce can adapt quickly enough through retraining and skill acquisition.

The apparent dichotomy between augmentation and automation may be overly simplistic. Evidence suggests AI often performs both functions simultaneously. Automation of certain tasks within a job [[Halal, W. et al. 2016](https://jfsdigital.org/wp-content/uploads/2017/01/JFS212Final%EF%BC%88%E5%B7%B2%E6%8B%96%E7%A7%BB%EF%BC%89-6.pdf)] might free up worker time. Whether this leads to workforce reduction (automation's displacement effect) or reallocation to new, potentially higher-value tasks depends critically on factors like firm strategy, the elasticity of demand for the firm's output (whether productivity gains translate into enough increased demand to retain workers), and the rate at which entirely new tasks are created within the economy [[Acemoglu, D. et al. 2024](https://shapingwork.mit.edu/wp-content/uploads/2023/10/Paper_Artificial-Intelligence-and-Jobs-Evidence-from-Online-Vacancies.pdf)]. Capturing this dynamic balance between task displacement, productivity effects, and new task creation remains a significant challenge for current economic models.

A crucial consideration often obscured by aggregate employment forecasts is the potential for significant churn within the labor market. Even if the net change in the total number of jobs is small or positive, AI could simultaneously destroy jobs in certain occupations and sectors while creating them in others. This process of "creative destruction" implies substantial worker displacement and reallocation. The transition costs associated with this churn, including periods of unemployment, the need for retraining, potential geographic relocation, and wage losses for displaced workers, can be immense for individuals and communities, even if macroeconomic employment figures appear stable. Therefore, focusing solely on net employment effects provides an incomplete picture; understanding the scale and nature of labor market transitions is essential for designing effective support policies.

#### Occupational Shifts and Skill Demand
Regardless of the net effect on employment numbers, AI is widely expected to drive significant shifts in the composition of work and the demand for skills. McKinsey projects an additional 12 million occupational transitions may be needed in the US alone by 2030 [[McKinsey, 2023](https://www.mckinsey.com/~/media/mckinsey/mckinsey%20global%20institute/our%20research/generative%20ai%20and%20the%20future%20of%20work%20in%20america/generative-ai-and-the-future-of-work-in-america-vf1.pdf)], a figure 25% higher than earlier estimates, indicating an accelerating pace of change. These transitions are unlikely to be evenly distributed. Workers in lower-wage jobs are estimated to be up to 14 times more likely to need to change occupations than those in the highest-wage positions, and most will require additional skills to do so successfully [[McKinsey, 2023](https://www.mckinsey.com/~/media/mckinsey/mckinsey%20global%20institute/our%20research/generative%20ai%20and%20the%20future%20of%20work%20in%20america/generative-ai-and-the-future-of-work-in-america-vf1.pdf)]. Women may also face a higher likelihood of needing to transition compared to men [[McKinsey, 2023](https://www.mckinsey.com/~/media/mckinsey/mckinsey%20global%20institute/our%20research/generative%20ai%20and%20the%20future%20of%20work%20in%20america/generative-ai-and-the-future-of-work-in-america-vf1.pdf)].

A notable shift is occurring in the types of jobs most affected. While earlier waves of automation primarily impacted routine manual and cognitive tasks, often concentrated in lower- and middle-wage roles [[Muro, M. et al. 2019](https://www.brookings.edu/wp-content/uploads/2019/01/2019.01_BrookingsMetro_Automation-AI_Report_Muro-Maxim-Whiton-FINAL-version.pdf)], AI's capabilities, particularly in areas like natural language processing and complex pattern recognition, mean that higher-wage, white-collar, knowledge-based occupations are increasingly exposed [[McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier)]. Empirical studies confirm that AI exposure at the firm level is associated with declines in demand for some previously sought-after skills, alongside the emergence of demand for entirely new skills [[Acemoglu, D. et al. 2024](https://shapingwork.mit.edu/wp-content/uploads/2023/10/Paper_Artificial-Intelligence-and-Jobs-Evidence-from-Online-Vacancies.pdf)]. This dynamic fuels concerns about a growing skills gap, with estimates suggesting as much as 39% of core worker skills could become outdated by 2030 [[WEF](https://sustainabilitymag.com/articles/wef-report-the-impact-of-ai-driving-170m-new-jobs-by-2030)]. Consequently, there is a perceived urgent need for large-scale reskilling and upskilling initiatives, fostering a culture of lifelong learning to enable workforce adaptation [[WEF](https://sustainabilitymag.com/articles/wef-report-the-impact-of-ai-driving-170m-new-jobs-by-2030)].

The impact of AI is demonstrably heterogeneous across multiple dimensions. Effects vary significantly not only by skill level [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)] and wage level [[McKinsey, 2023](https://www.mckinsey.com/~/media/mckinsey/mckinsey%20global%20institute/our%20research/generative%20ai%20and%20the%20future%20of%20work%20in%20america/generative-ai-and-the-future-of-work-in-america-vf1.pdf)], but also by occupation [[WEF](https://sustainabilitymag.com/articles/wef-report-the-impact-of-ai-driving-170m-new-jobs-by-2030)], industry [[McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier)], geography [[WEF](https://sustainabilitymag.com/articles/wef-report-the-impact-of-ai-driving-170m-new-jobs-by-2030)], gender [[McKinsey, 2023](https://www.mckinsey.com/~/media/mckinsey/mckinsey%20global%20institute/our%20research/generative%20ai%20and%20the%20future%20of%20work%20in%20america/generative-ai-and-the-future-of-work-in-america-vf1.pdf)], and age [[IMF](https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity)]. For instance, Anthropic's index found AI usage peaking in mid-to-high wage occupations like programmers and data scientists, but dropping off at both the lowest (perhaps due to task nature, e.g., manual dexterity) and highest ends (perhaps due to complexity or bespoke nature of tasks) [30]. The IMF notes that advanced economies face greater immediate risks but also more opportunities from AI compared to developing economies, due to the higher proportion of jobs susceptible to AI's influence [[IMF](https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity)]. This multidimensional heterogeneity implies that aggregate forecasts, while useful for illustrating potential scale, inevitably mask crucial distributional consequences. Understanding who benefits, who loses, and where interventions are most needed requires a granular analytical approach that considers these intersecting factors, a key limitation in current research.

### Wage Effects and the Future of Inequality
AI's potential impact on wages and income distribution is another area of significant divergence and concern. Optimistic scenarios link AI-driven productivity gains to potential wage increases, assuming these gains are shared with the workforce [[CBO](https://www.cbo.gov/publication/61147), [Aghion, P. et al. 2017](https://www.nber.org/system/files/working_papers/w23928/w23928.pdf)]. If AI complements workers, enhancing their productivity, their wages could rise accordingly [[CBO](https://www.cbo.gov/publication/61147), [Aghion, P. et al. 2017](https://www.nber.org/system/files/working_papers/w23928/w23928.pdf)]. Some studies have found that earlier forms of AI boosted the wages of specific skilled workers, and generative AI has shown potential to help less experienced workers improve their performance more quickly, potentially leading to faster wage growth for them [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)]. Furthermore, if the economy successfully navigates occupational transitions towards roles requiring higher skills or leveraging AI effectively, there could be an overall shift towards higher-wage jobs [[McKinsey, 2023](https://www.mckinsey.com/~/media/mckinsey/mckinsey%20global%20institute/our%20research/generative%20ai%20and%20the%20future%20of%20work%20in%20america/generative-ai-and-the-future-of-work-in-america-vf1.pdf)].

Conversely, pessimistic scenarios emphasize the risk of wage stagnation or decline, particularly for workers whose tasks are easily automated by AI. If AI primarily substitutes for human labor, it could reduce overall labor demand, putting downward pressure on wages and hiring, especially if the productivity effects are modest or if the benefits accrue primarily to capital owners rather than labor [[CBO](https://www.cbo.gov/publication/61147), [Aghion, P. et al. 2017](https://www.nber.org/system/files/working_papers/w23928/w23928.pdf)]. Historical analysis suggests automation in certain sectors has been linked to wage decline [[SEO](https://seo.ai/blog/ai-replacing-jobs-statistics)]. There is a concern of the potential shift in the distribution of income away from labor and towards capital. If AI primarily functions as a substitute for labor, automating tasks previously performed by humans, economic theory suggests it could decrease the overall demand for labor relative to capital, thereby reducing labor's share of national income and increasing the share accruing to owners of capital and AI technologies [[Korinek, A. et al. 2021](https://www.nber.org/papers/w28453)].

Beyond the capital-labor split, AI is expected to reshape the wage distribution among workers. A common hypothesis is that AI will increase the "skill premium," benefiting workers whose skills are complementary to AI (e.g., those involved in developing, managing, or utilizing AI systems creatively) while depressing wages for those whose skills are easily substitutable [[Acemoglu, D. et al. 2019](https://www.aeaweb.org/articles?id=10.1257/jep.33.2.3)]. This could exacerbate existing wage inequality. Some models predict a polarization of the labor market, where demand increases for high-skill cognitive jobs (complemented by AI) and potentially for low-skill manual jobs (currently difficult to automate), while demand and wages decline for middle-skill routine jobs that are highly susceptible to automation. Empirical studies examining the relationship between automation exposure and wages provide mixed but often concerning evidence, with some finding negative wage impacts for workers in occupations with higher automation risk scores [[Acemoglu, D. et al. 2024](https://shapingwork.mit.edu/wp-content/uploads/2023/10/Paper_Artificial-Intelligence-and-Jobs-Evidence-from-Online-Vacancies.pdf)].

There is also evidence suggesting AI could exacerbate wage inequality within firms [[AEA](https://www.aeaweb.org/conference/2020/preliminary/paper/Tz2HdRna)]. A broader concern is labor market polarization, where workers who possess the skills to effectively utilize AI see their productivity and wages increase, while those who cannot adapt fall further behind [[IMF](https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity)]. If AI disproportionately complements high-income workers, it could lead to a significant widening of the wage gap [[IMF](https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity)]. Moreover, the productivity gains captured by firms adopting AI are likely to boost returns to capital, which tend to be concentrated among higher earners, further intensifying inequality [[IMF](https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity)]. Reflecting these concerns, the IMF concludes that in most scenarios, AI is likely to worsen overall income inequality [[IMF](https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity)]. Structural factors related to the AI industry itself, such as high fixed costs, returns to scale in data and computing power, and network effects, could lead to increased market concentration. This concentration might allow dominant firms to capture a disproportionate share of the value created, potentially limiting broad-based wage growth [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)]. Additionally, AI-powered tools like dynamic pricing algorithms could potentially enhance firms' market power and lead to supra-competitive prices, further shifting surplus away from consumers and potentially workers [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)].

Empirical evidence on AI's aggregate wage effects remains limited and inconclusive. Studies examining recent years have generally failed to detect a significant relationship between occupational or industry-level AI exposure and overall wage growth, suggesting widespread effects have yet to materialize or are difficult to isolate [[Acemoglu, D. et al. 2024](https://shapingwork.mit.edu/wp-content/uploads/2023/10/Paper_Artificial-Intelligence-and-Jobs-Evidence-from-Online-Vacancies.pdf)]. While the dominant expectation leans towards increased inequality [[IMF](https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity)], some theoretical arguments suggest AI could potentially reduce inequality by automating tasks previously performed by high-skilled workers, thereby narrowing the gap with lower-skilled workers [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)], or by lowering barriers to skill acquisition and improving access to opportunities [[Mayer, H. et al.](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work)].

The ultimate impact of AI on wages appears highly contingent not just on the technology itself, but critically on the interplay between technology, market power, and policy responses. The distribution of AI's economic benefits will be heavily influenced by factors such as the bargaining power of labor (affected by union density and labor laws - factors that are understudied), the competitive structure of markets (influenced by antitrust policy), minimum wage laws, and government policies regarding taxation (e.g., how capital gains versus labor income are taxed), redistribution (e.g., social safety nets, unemployment benefits, potential universal basic income schemes), and investment in public goods like education and retraining programs [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)]. This implies that wage outcomes are not technologically predetermined but are subject to societal choices and institutional design. Predicting these outcomes therefore requires models capable of incorporating these endogenous institutional factors and policy feedback loops, representing a significant frontier for research.

| Study / Source                      | Time Horizon           | Key Productivity Projection                                                                           | Key Employment Projection (Exposure / Displacement / Creation)                                       | Key Wage / Inequality Projection                                                   | Core Methodology / Assumptions                                       |
| ----------------------------------- | ---------------------- | ----------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- | -------------------------------------------------------------------- |
| **[[McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier)]**               | Annual / 2040          | +\$2.6 – 4.4 T per year from GenAI use-cases; **+0.1 – 0.6 pp** to annual productivity growth by 2040 | 60 – 70 % of work-time automatable; 50 % of activities automated by 2030-2060 (mid-point 2045)       | Primarily augments higher-wage/edu knowledge work; large worker transitions needed | Use-case analysis, expert assessment, staged adoption scenarios      |
| **WEF** [[Forbes](https://www.forbes.com/councils/forbestechcouncil/2024/03/12/the-future-of-work-embracing-ais-job-creation-potential/), [WEF](https://sustainabilitymag.com/articles/wef-report-the-impact-of-ai-driving-170m-new-jobs-by-2030)]                            | 2025 / 2030            | Implicitly positive                                                                                   | **2025:** 85 M displaced / 97 M created · **2030:** 92 M displaced / 170 M created                   | Large skill-shift; skills gap seen as main barrier                                 | Global employer surveys across industries & economies                |
| **[IMF](https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity)**                            | Near / Medium term     | Implicitly positive (productivity gains for some)                                                     | ≈ 40 % jobs exposed (60 % in advanced, 40 % in EM, 26 % in LI); mix of replacement & complementarity | Likely higher inequality; polarization between AI-enabled & other workers          | Staff analysis; task-exposure mapping by occupation                  |
| **Goldman Sachs** [[Howarth, J. 2025](https://explodingtopics.com/blog/ai-replacing-jobs), [SEO](https://seo.ai/blog/ai-replacing-jobs-statistics)]                  | Medium term            | Implicitly positive                                                                                   | Up to **300 M** full-time jobs automatable worldwide (highest in US/Europe)                          | (Not specified)                                                                    | Economic analysis focused on generative-AI task automation potential |
| **[Acemoglu, D. 2025](https://economics.mit.edu/sites/default/files/2024-04/The%20Simple%20Macroeconomics%20of%20AI.pdf)**                 | Next decade            | Modest productivity gains                                                                             | Task displacement emphasis based on current tech capabilities                                        | Modest wage effects                                                                | Empirical, task-based cost-saving model extrapolating current AI     |
| **[Korinek & Suh 2024](https://www.nber.org/papers/w32255)**            | Long term (toward AGI) | Productivity could collapse wages or spur explosive growth                                            | Employment outcomes depend on automation thresholds                                                  | Wage outcomes likewise threshold-dependent                                         | Theoretical model linking comp. complexity & automation thresholds   |
| **[Epoch AI's GATE, 2025](https://arxiv.org/abs/2503.04941)**             | Long term              | Growth driven by compute & investment; includes adjustment costs                                      | Labor dynamics modeled but simplified                                                                | (Not specified)                                                                    | Integrated compute→automation mapping; macro model with frictions    |
**Table 1: Comparative Summary of Selected AI-Impact Forecasts**. This table highlights the significant divergence in quantitative forecasts and the uncertainty surrounding AI's economic impact. The differences are driven not just by varying parameters but by fundamentally different assumptions about the nature of AI, its interaction with labor, and the broader economic and policy environment. *Note - This distills headline figures and methods; each study includes nuance and scenario details not fully captured here.* 

## Modeling the Unpredictable: Scrutinizing Current Approaches
The wide divergence in forecasts presented in the previous section stems not only from inherent uncertainties about AI's future but also from significant limitations in the methodologies used to model its impact. Critically evaluating these approaches is essential for understanding the reliability of current predictions and identifying areas for improvement.

### Case Studies in Forecasting 
Here we present critiques of three recent modeling efforts: [Korinek & Suh 2024](https://www.nber.org/papers/w32255), [Acemoglu, D. 2025](https://economics.mit.edu/sites/default/files/2024-04/The%20Simple%20Macroeconomics%20of%20AI.pdf), [Epoch AI's GATE, 2025](https://arxiv.org/abs/2503.04941), illustrating common challenges. 

#### Korinek & Suh (2024)
This work provides a valuable theoretical exploration of potential long-run scenarios under AGI, linking outcomes like wage collapse or explosive growth to parameters such as computational complexity and automation thresholds. Its strength lies in pushing the boundaries of thinking about potentially radical futures. However, its limitations are significant for near-to-medium term relevance. By heavily emphasizing computational power as the primary driver and constraint, it largely abstracts away from crucial real-world frictions that inevitably shape the pace and pattern of automation. Factors such as regulatory landscapes, the complexities of societal acceptance and trust, data privacy regulations, the need for specialized hardware, and task-specific physical limitations (like dexterity) are inadequately incorporated. Its treatment of labor as a largely homogeneous input overlooks the critical dimensions of skill heterogeneity, task specialization, and the prevalence of hybrid automation scenarios where humans and machines work collaboratively, rather than AI achieving full task replacement.

#### Acemoglu (2025)
In contrast, Acemoglu's model offers an empirically grounded, task-based approach focused on estimating near-term impacts over the next decade. By analyzing current AI capabilities, task exposure, and potential cost savings, it provides detailed, albeit modest, forecasts for productivity and wages. Its strength is its empirical grounding in present realities. However, this focus on current capabilities and incremental task automation becomes a limitation when considering AI's potential for transformative change. The model underestimates AI's capacity to generate entirely new tasks, industries, and forms of economic activity, which could fundamentally alter labor market dynamics beyond simple substitution or augmentation within existing structures. Its reliance on extrapolating from current AI functionalities may prove unreliable given the rapid, non-linear, and often unpredictable trajectory of AI development. By concentrating on task-specific productivity improvements, it risks missing the larger picture of recombinative innovation and economic restructuring that AI might enable.

#### Epoch AI GATE (2025)
The GATE model represents an ambitious attempt at integration, combining a compute-driven model of AI development with automation mapping and macroeconomic modeling that includes endogenous investment decisions and adjustment costs. Its strength lies in explicitly incorporating certain real-world frictions, such as hardware production bottlenecks, capital adjustment costs, and uncertainty surrounding AI capabilities, thereby capturing important interactions between technological progress, investment cycles, and economic outcomes. Despite its comprehensiveness, the model is still acknowledged to simplify the complexities of task heterogeneity and the dynamic adjustment processes within labor markets, particularly the challenges associated with large-scale worker reallocation and the societal capacity to adapt to rapid technological shifts.

A crucial overarching critique applicable to all three studies is their insufficient attention to the differentiated impacts of automation across diverse skill levels and demographic groups. They also largely neglect the significant socio-economic consequences of widespread displacement, such as the costs and effectiveness of retraining programs, and fail to adequately incorporate the mediating role of institutional contexts - including labor laws, union influence, cultural norms regarding technology, and specific public policies designed to mitigate adverse effects or shape AI deployment. The stark divergence in their predictions shows a fundamental lack of consensus and a clear understanding of AI's likely trajectory and impact, signaling a pressing need for more robust and comprehensive modeling frameworks. Our argument here is not that every study/method needs to take into account all possible details and scenarios, but rather to understand where the deficiencies in models are before we take their forecasts too seriously for policy making purposes. 

### General Methodological Challenges in AI Impact Studies 
Despite a number of studies attempting to forecast AI's socio-economic consequences, our ability to predict the future with any degree of certainty remains limited. Current methodologies and models suffer from shortcomings that constrain the reliability and utility of their outputs.

#### Predicting Technological Breakthroughs
Forecasting the pace and nature of AI progress itself is inherently difficult [[CBO](https://www.cbo.gov/publication/61147), [Aghion, P. et al. 2017](https://www.nber.org/system/files/working_papers/w23928/w23928.pdf)]. AI development, particularly towards more general capabilities (AGI), is characterized by uncertainty and the potential for sudden breakthroughs that defy simple extrapolation [[Halal, W. et al. 2016](https://jfsdigital.org/wp-content/uploads/2017/01/JFS212Final%EF%BC%88%E5%B7%B2%E6%8B%96%E7%A7%BB%EF%BC%89-6.pdf)]. Models often rely on extending current trends or capabilities [[Acemoglu, D. 2025](https://economics.mit.edu/sites/default/files/2024-04/The%20Simple%20Macroeconomics%20of%20AI.pdf)], which may significantly underestimate or mischaracterize future developments, especially given the accelerating pace observed in recent years [[Muro, M. et al. 2019](https://www.brookings.edu/wp-content/uploads/2019/11/2019.11.20_BrookingsMetro_What-jobs-are-affected-by-AI_Report_Muro-Whiton-Maxim.pdf)]. If AI progress is non-linear or involves emergent capabilities, extrapolations based on past trends or existing theoretical frameworks may prove inadequate. The potential for AI to fundamentally alter the process of innovation itself adds another layer of complexity that current economic models are ill-equipped to handle.

#### Modeling Task Dynamics
Accurately mapping evolving AI capabilities onto the vast landscape of human work tasks is a complex, ongoing challenge [[Muro, M. et al. 2019](https://www.brookings.edu/wp-content/uploads/2019/11/2019.11.20_BrookingsMetro_What-jobs-are-affected-by-AI_Report_Muro-Whiton-Maxim.pdf)]. While methods like analyzing patent text or vacancy data to infer task exposure exist [[Acemoglu, D. et al. 2024](https://shapingwork.mit.edu/wp-content/uploads/2023/10/Paper_Artificial-Intelligence-and-Jobs-Evidence-from-Online-Vacancies.pdf)], they struggle to keep pace with rapid AI advancements. A deeper difficulty lies in modeling the creation of entirely new tasks and occupations that emerge as a consequence of AI deployment. Existing models often focus on automation of existing tasks, neglecting the potential job creation stemming from novel applications and industries enabled by AI [[Acemoglu, D. 2025](https://economics.mit.edu/sites/default/files/2024-04/The%20Simple%20Macroeconomics%20of%20AI.pdf), [Acemoglu, D. et al. 2024](https://shapingwork.mit.edu/wp-content/uploads/2023/10/Paper_Artificial-Intelligence-and-Jobs-Evidence-from-Online-Vacancies.pdf)].

#### Accounting for Real-World Frictions
Economic models frequently abstract away from the messy realities that govern technology diffusion and impact. These include:

1. **Implementation Hurdles**: Significant costs associated with adopting AI, integrating it into existing workflows, and undertaking necessary organizational changes can slow diffusion [[Brynjolfsson, E. et al. 2019](https://www.nber.org/system/files/working_papers/w24001/w24001.pdf)]. Historical analysis shows implementation lags are common for major technologies [[Brynjolfsson, E. et al. 2019](https://www.nber.org/system/files/working_papers/w24001/w24001.pdf)].
2. **Institutional & Social Factors**: Regulatory frameworks, data governance policies, labor market regulations, and intellectual property rights significantly shape AI deployment [[Makridis, C. A. et al. 2024](https://academic.oup.com/spp/article-abstract/51/3/557/7595834?redirectedFrom=fulltext)]. Social acceptance, public trust, ethical concerns, and cultural attitudes towards automation also play crucial roles but are difficult to quantify and model [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)].
3. **Paradigms, Algorithms & Architectures**: The language modeling paradigm may provide diminishing returns in the near future, while LLMs could be a dead end in terms of truly long-horizon agentic tasks, few-shot generalization, or novel scientific discovery. New algorithmic breakthroughs might be a bottleneck for AI progress.   
4. **Task-Specific Constraints**: Many tasks involve physical dexterity, complex environmental interaction, or tacit knowledge that remains challenging for current AI, limiting automation possibilities beyond purely digital or cognitive domains. 

#### Economic Assumptions
Many models treat key variables like labor, capital, or even AI technology itself as uniform entities. This masks critical heterogeneity in skills, firm capabilities, and AI applications, leading to potentially misleading aggregate conclusions. Incorporating granular data on skills and tasks is essential but challenging. Models often assume perfect competition, representative agents, and straightforward relationships (like constant elasticities of substitution between capital, labor, and AI) that fail to capture the messy realities of economic transitions [[Acemoglu, D. et al. 2019](https://www.aeaweb.org/articles?id=10.1257/jep.33.2.3)]. Modeling endogenous technological change, where the pace and direction of innovation respond to economic incentives and policy, remains a major challenge. Capturing complex feedback loops between technological adoption, market structure, consumer behavior, and institutional responses is often beyond the scope of tractable models.

AI's impact ripples through the economy via complex feedback mechanisms that are difficult to model comprehensively. Productivity gains can affect prices, demand, and investment. Wage changes impact consumption and labor supply. International trade patterns and global competition add further layers of complexity [[Makridis, C. A. et al. 2024](https://academic.oup.com/spp/article-abstract/51/3/557/7595834?redirectedFrom=fulltext)]. Models often simplify these interdependencies or ignore global linkages.

Many studies suffer from a partial equilibrium focus. They might analyze the impact of AI on specific occupations or industries in isolation, without fully accounting for general equilibrium effects that ripple throughout the economy. These include changes in relative prices, shifts in consumer demand patterns, resource reallocation across sectors, and adjustments in international trade flows, all of which can significantly alter the ultimate impact of AI adoption. Studies also struggle to incorporate human adaptation dynamically. They may treat skills, preferences, and societal norms as relatively fixed, underestimating the capacity of individuals and institutions to learn, adapt, and change their behavior or values over a multi-decade horizon. Workers acquire new skills, firms develop new business models, consumers change their preferences, and societies may evolve new norms around work, leisure, and technology use in ways that are difficult to anticipate. 

Studies have a tendency to present isolated projections for specific variables (e.g., job losses, productivity gains) rather than developing coherent, integrated scenarios. A realistic assessment requires understanding how technological advancements interact with economic dynamics, policy interventions, and societal responses simultaneously. For example, widespread automation might trigger calls for universal basic income (UBI); the implementation (or lack thereof) of UBI would then feed back into labor supply decisions, consumption patterns, and potentially even the direction of future innovation. Current models rarely capture such policy endogeneity, the two-way interaction where policy shapes AI's impact, and AI's impact shapes policy responses. Without integrating these interdependencies, projections remain fragmented and potentially misleading guides for long-term strategy.

#### Measurement Issues
Simply defining and measuring "AI" and its adoption across the economy is non-trivial [[Muro, M. et al. 2019](https://www.brookings.edu/wp-content/uploads/2019/11/2019.11.20_BrookingsMetro_What-jobs-are-affected-by-AI_Report_Muro-Whiton-Maxim.pdf)]. Distinguishing the causal impact of AI from other simultaneous economic trends (e.g., globalization, demographic shifts, other technological changes) is a persistent econometric challenge [[Brynjolfsson, E. et al. 2019](https://www.nber.org/system/files/working_papers/w24001/w24001.pdf)]. Initiatives like the Anthropic Economic Index attempt to provide better real-time measurement based on usage data, but comprehensive measurement remains difficult [[Anthropic, 2025](https://www.anthropic.com/news/the-anthropic-economic-index)]. Robust empirical analysis requires granular, high-frequency data on the actual adoption and use of specific AI technologies by firms, the evolving task content of jobs, shifts in skill demands, worker transitions between jobs and sectors, the prevalence of non-standard work arrangements facilitated by AI platforms, and reliable metrics for well-being. Such data are often scarce, proprietary, or non-existent, forcing researchers to rely on proxies (like patent data, occupational task descriptions, or broad industry classifications) that may not accurately reflect the nuances of AI deployment [[Babina, T. et al. 2024](https://www.nber.org/papers/w31325), [Acemoglu, D. et al. 2024](https://shapingwork.mit.edu/wp-content/uploads/2023/10/Paper_Artificial-Intelligence-and-Jobs-Evidence-from-Online-Vacancies.pdf)].

Research examining the impact of automation risk exposure on labor market outcomes [[Acemoglu, D. et al. 2024](https://shapingwork.mit.edu/wp-content/uploads/2023/10/Paper_Artificial-Intelligence-and-Jobs-Evidence-from-Online-Vacancies.pdf)] often relies on constructing indices of exposure based on occupational task content and linking them to observed outcomes. While valuable, such approaches face challenges in establishing causality definitively, depend heavily on the accuracy and stability of task-based exposure measures, and may struggle to generalize findings from specific contexts or time periods to predict future impacts of fundamentally new AI capabilities. Similarly, studies analyzing firm-level AI adoption and productivity [[Babina, T. et al. 2024](https://www.nber.org/papers/w31325)] provide crucial insights into micro-level dynamics but often face data constraints (e.g., measuring AI capital accurately, obtaining representative samples) and challenges in isolating the causal effect of AI from other confounding factors (like management quality or complementary investments). The external validity of findings from early adopters (often large, frontier firms) to the broader economy also requires careful consideration.

#### Socio-political Context
There is a common implicit assumption within many economic forecasts of a relatively stable socio-political context. These models often fail to account for the possibility that AI itself could be a catalyst for significant shifts in political economy. The prospect of large-scale labor displacement or dramatic increases in inequality [[Korinek, A. et al. 2021](https://www.nber.org/papers/w28453)] could fuel social unrest, lead to demands for radical policy interventions (e.g., wealth taxes, fundamental changes to social contracts), or alter geopolitical dynamics as nations compete for AI dominance. These political and institutional responses, while difficult to model, are not merely exogenous factors but are likely to be endogenous to the AI transition itself. Ignoring these potential feedback loops limits the realism of long-term forecasts, especially over a multi-decade horizon where such shifts become increasingly plausible.

#### Transformative Potential and Balancing Perspectives
A recurring tension exists between modeling approaches focused on incremental, empirically measurable changes based on current technology (like Acemoglu's [[Acemoglu, D. 2025](https://economics.mit.edu/sites/default/files/2024-04/The%20Simple%20Macroeconomics%20of%20AI.pdf)]) and those attempting to grapple with potentially transformative, but highly uncertain, long-term scenarios (like [Korinek & Suh 2024](https://www.nber.org/papers/w32255)). Bridging this gap and developing models that are empirically grounded yet capable of exploring plausible pathways to significant structural change in the medium term remains a key challenge.

The inherent assumptions embedded within different models reflect fundamentally different conceptions of AI itself. Some models implicitly treat AI primarily as an automation tool driven by cost-benefit calculations at the task level. Others emphasize the role of computational resources and investment cycles as key drivers of capability development. Still others focus on the augmentation potential and collaborative aspects of human-AI interaction. These underlying conceptual differences inevitably lead to divergent predictions about AI's economic role and impact. Progress in forecasting requires not only better data and more sophisticated techniques but also a clearer articulation and testing of these foundational assumptions about AI's nature, evolution, and interaction with the economy. Comparing results from models built on explicitly different paradigms of AI development is important for understanding the range of possibilities and the sensitivity of outcomes to core assumptions. Integrating the full spectrum of perspectives, from optimistic visions of abundance to pessimistic scenarios of disruption, into coherent and testable modeling frameworks is necessary to move beyond polarized debates towards a more nuanced understanding [[AEA](https://www.aeaweb.org/conference/2020/preliminary/paper/Tz2HdRna)].

## AI and Human Flourishing
Synthesizing the impacts on labor, productivity, and capital, the ultimate effect of AI on aggregate economic growth is a key question. And while economic metrics are crucial, assessment of AI's impact must extend to its effects on broader dimensions of human flourishing - the aspects that contribute to a life well-lived, encompassing well-being, agency, social cohesion, equity, and meaning.

### Economic Growth
Optimistic projections envision AI significantly accelerating long-run growth rates, driven by sustained productivity improvements and potentially by AI's role in accelerating scientific discovery and innovation itself [[Agrawal, A. et al. 2018](https://www.predictionmachines.ai/)]. AI tools could enhance R&D processes, leading to faster development of new technologies and solutions across various fields, creating a positive feedback loop for growth. However, potential countervailing factors could dampen AI's positive impact on growth. Standard economic theory posits diminishing returns, even to powerful technologies like AI. Baumol's "cost disease" might become more pronounced if AI primarily boosts productivity in easily automatable sectors while less automatable, labor-intensive sectors (like healthcare, education, or personal services) account for a growing share of the economy and employment, potentially dragging down aggregate productivity growth. If AI leads to sharply increased inequality and wage stagnation for a large portion of the population [[Korinek, A. et al. 2021](https://www.nber.org/papers/w28453)], this could create demand-side constraints on growth, as consumption patterns shift and aggregate demand weakens. Misallocation of resources, whether towards rent-seeking activities enabled by AI or due to market concentration hindering efficient capital deployment, could also limit the overall growth dividend. The net effect on long-term economic growth remains uncertain and likely contingent on how these competing forces play out and how effectively policies manage the transition.

### The Changing Nature of Work: Quality, Autonomy, and Meaning
AI's integration into the workplace promises to reshape not just how much work is done, but the experience of work itself, with potentially mixed consequences for job quality. On the positive side, AI could enhance job quality by automating tedious, repetitive, or physically dangerous tasks, freeing human workers to focus on more engaging activities that require creativity, critical thinking, complex problem-solving, and interpersonal skills like empathy [[Marr, B.](https://bernardmarr.com/what-is-the-impact-of-artificial-intelligence-ai-on-society/)]. This shift could potentially lead to increased job satisfaction and a greater sense of accomplishment [[Marr, B.](https://bernardmarr.com/what-is-the-impact-of-artificial-intelligence-ai-on-society/)]. AI tools can also serve as powerful assistants, augmenting human capabilities and potentially reducing errors related to fatigue [[Tai, M. C-T. 2020](https://pmc.ncbi.nlm.nih.gov/articles/PMC7605294/)]. If productivity gains are substantial and shared equitably, they could also potentially lead to reduced working hours and improved work-life balance.

However, significant concerns exist regarding the potential degradation of work quality. The encroachment of AI into complex cognitive tasks previously considered the domain of skilled professionals could lead to deskilling or de-professionalization in some fields [[Anderson, J. et. al, 2025](https://imaginingthedigitalfuture.org/reports-and-publications/being-human-in-2035/)]. The rise of algorithmic management, using AI to assign tasks, monitor performance, and even make disciplinary decisions, raises concerns about increased surveillance, reduced worker autonomy, and a more pressurized work environment [[Spitko, E. G. 2024](https://digitalcommons.lib.uconn.edu/cgi/viewcontent.cgi?article=1614&context=law_review)]. There's a risk that AI systems, optimized for efficiency or standardization, could lead to work becoming more rigid, less creative, and ultimately less fulfilling, potentially functioning as "Mediocrity Engines" that stifle ingenuity [[Anderson, J. et. al, 2025](https://imaginingthedigitalfuture.org/reports-and-publications/being-human-in-2035/)]. The increasing use of AI decision tools in critical employment processes like recruitment, hiring, performance evaluation, compensation, promotion, and termination [[Spitko, E. G. 2024](https://digitalcommons.lib.uconn.edu/cgi/viewcontent.cgi?article=1614&context=law_review)] shifts decision-making power away from human managers and potentially workers themselves. While proponents argue these tools can reduce human bias and base decisions on empirical data [[Spitko, E. G. 2024](https://digitalcommons.lib.uconn.edu/cgi/viewcontent.cgi?article=1614&context=law_review)], critics worry about opaque algorithms making consequential decisions without clear justification or avenues for appeal, thereby undermining worker agency and potentially human dignity [[Spitko, E. G. 2024](https://digitalcommons.lib.uconn.edu/cgi/viewcontent.cgi?article=1614&context=law_review)]. Maintaining meaningful human oversight and judgment in AI-driven decision-making processes is crucial for preserving autonomy and ensuring fairness [[Walther, C. 2025](https://knowledge.wharton.upenn.edu/article/why-hybrid-intelligence-is-the-future-of-human-ai-collaboration/)].

Some experts express concern that as AI systems increasingly match or surpass human capabilities in intellectual and creative domains, it could lead to a sense of demoralization or existential unease about humanity's unique role [[Anderson, J. et. al, 2025](https://imaginingthedigitalfuture.org/reports-and-publications/being-human-in-2035/)]. Conversely, AI could also be viewed as a powerful tool that augments human potential, enabling individuals to tackle more ambitious challenges, acquire new skills more easily, and engage in more creative and fulfilling endeavors [[Mayer, H. et al.](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work)]. The ultimate effect on meaning may depend on how AI is integrated into work and society, whether it is perceived primarily as a replacement or as a collaborative partner.

### Equity, Bias, and Social Cohesion in the Age of AI
AI's societal impact extends into issues of equity, fairness, and social cohesion, with potential for both positive and negative outcomes. A primary concern is the potential for AI to exacerbate existing inequalities. As discussed previously, many analyses predict AI will likely worsen income inequality by disproportionately benefiting capital owners and high-skilled workers who can leverage the technology, while potentially displacing lower-skilled workers or depressing their wages [[IMF](https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity)]. Beyond income, AI could widen digital divides, creating deeper gaps between individuals, communities, and nations with access to AI tools and the skills to use them, and those without [[CTF](https://static1.squarespace.com/static/61519ebe46a933184f1a18a3/t/65b26cda3d1d392fba824479/1706192091391/Executive+Summary+New+Perspectives+on+AI+Futures.pdf)]. This unequal distribution of benefits and opportunities could further concentrate wealth and power [[Tai, M. C-T. 2020](https://pmc.ncbi.nlm.nih.gov/articles/PMC7605294/)], posing risks to democratic governance and individual agency [[Acemoglu, D. et al. 2023](https://shapingwork.mit.edu/power-and-progress/)]. The proliferation of AI-powered surveillance technologies could erode privacy and potentially chills dissent, constraining autonomy. Algorithmic bias represents another major equity challenge. AI systems are trained on data, and if that data reflects historical or societal biases (e.g., related to race, gender, age, or other characteristics), the AI can perpetuate or even amplify those biases [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)]. This has implications in areas like hiring (where AI screening tools might discriminate against certain groups [[Spitko, E. G. 2024](https://digitalcommons.lib.uconn.edu/cgi/viewcontent.cgi?article=1614&context=law_review)]), credit scoring, loan applications, and even criminal justice. Addressing algorithmic bias requires careful attention to data sourcing, model design, ongoing auditing, and transparency [[Walther, C. 2025](https://knowledge.wharton.upenn.edu/article/why-hybrid-intelligence-is-the-future-of-human-ai-collaboration/)], and may disproportionately impact already marginalized groups if not handled proactively [[Rege, M. et al. 2024](https://news.stthomas.edu/generative-ais-real-world-impact-on-job-markets/)]. 

Some commentators worry that increased reliance on AI for communication, information, and even companionship could diminish face-to-face human interaction and weaken social bonds [[Tai, M. C-T. 2020](https://pmc.ncbi.nlm.nih.gov/articles/PMC7605294/)]. The potential for AI-driven misinformation and the creation of echo chambers, mirroring issues seen with social media, poses a threat to shared understanding and social trust [[Hemment, D. 2025](https://impact.ed.ac.uk/opinion/why-the-humanities-must-shape-the-future-of-ai/)]. The increasing sophistication of AI agents might even blur the lines between human and artificial personalities, potentially creating confusion or eroding authenticity in social interactions [[Anderson, J. et. al, 2025](https://imaginingthedigitalfuture.org/reports-and-publications/being-human-in-2035/)].

However, AI also holds potential to enhance equity and access in certain domains. By lowering skill barriers for some tasks or providing personalized education and training, AI could potentially expand opportunities for individuals who previously faced disadvantages [[Mayer, H. et al.](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work)]. AI applications in areas like healthcare diagnostics [[Tai, M. C-T. 2020](https://pmc.ncbi.nlm.nih.gov/articles/PMC7605294/)] or credit scoring could, if designed carefully to mitigate bias, improve access for underserved populations. Realizing these positive potentials, however, requires deliberate effort to ensure equitable deployment and access to AI technologies and their benefits [[CTF](https://static1.squarespace.com/static/61519ebe46a933184f1a18a3/t/65b26cda3d1d392fba824479/1706192091391/Executive+Summary+New+Perspectives+on+AI+Futures.pdf)].

### Individual Well-being: Cognitive, Emotional, and Existential Dimensions
AI's influence extends to the individual level, affecting cognitive functions, emotional experiences, and even our sense of self. Cognitively, concerns have been raised about the potential for over-reliance on AI systems to lead to an atrophy of certain human cognitive skills, such as critical thinking, memory, or navigation, a phenomenon termed "self-inflicted AI dementia" [[Anderson, J. et. al, 2025](https://imaginingthedigitalfuture.org/reports-and-publications/being-human-in-2035/)]. If AI consistently provides answers or performs cognitive tasks for us, our own abilities in those areas might diminish over time. Conversely, AI also holds potential to enhance human cognition. It can serve as a powerful tool for learning, providing access to vast amounts of information and personalized educational experiences [[Anderson, J. et. al, 2025](https://imaginingthedigitalfuture.org/reports-and-publications/being-human-in-2035/)]. AI can act as a creative partner, stimulating new ideas and augmenting human innovative thinking [[Mayer, H. et al.](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/superagency-in-the-workplace-empowering-people-to-unlock-ais-full-potential-at-work)].

Emotionally, AI's impact is multifaceted. On one hand, AI-powered applications like socially assistive robots are being developed to provide companionship and therapeutic support, particularly for vulnerable populations like the elderly, potentially alleviating loneliness and anxiety [[Tai, M. C-T. 2020](https://pmc.ncbi.nlm.nih.gov/articles/PMC7605294/)]. AI systems integrated into healthcare may improve diagnostics and treatment planning, reducing stress associated with medical uncertainty [[Tai, M. C-T. 2020](https://pmc.ncbi.nlm.nih.gov/articles/PMC7605294/)]. On the other hand, the increasing sophistication of AI in mimicking human emotion raises concerns about "outsourced empathy," where reliance on AI for emotional support might displace genuine human connection [[Anderson, J. et. al, 2025](https://imaginingthedigitalfuture.org/reports-and-publications/being-human-in-2035/)]. Additionally, the economic anxieties and uncertainties associated with AI-driven job displacement or workplace changes can significantly impact emotional well-being [[Hemment, D. 2025](https://impact.ed.ac.uk/opinion/why-the-humanities-must-shape-the-future-of-ai/)].

Existentially, the rise of increasingly capable AI prompts fundamental questions about what it means to be human. As AI demonstrates proficiency in domains once considered uniquely human, such as complex reasoning, artistic creation, and even emotional expression, it challenges our self-perception and our place in the world. Concerns about losing control over powerful AI systems [[Tai, M. C-T. 2020](https://pmc.ncbi.nlm.nih.gov/articles/PMC7605294/)] or seeing human agency diminished in critical life domains [[Spitko, E. G. 2024](https://digitalcommons.lib.uconn.edu/cgi/viewcontent.cgi?article=1614&context=law_review)] contribute to these existential anxieties. Some experts even raise long-term concerns about existential risks associated with superintelligent AI, although the probability and timeline of such scenarios are highly debated [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)].

### Human Agency and the Need for Value Alignment
Navigating the potential impacts on flourishing requires a focus on preserving human agency and ensuring that AI development and deployment align with human values. A critical imperative is ensuring that AI systems serve human goals and reflect ethical principles [[Horvitz, E. 2023](https://blogs.microsoft.com/blog/2023/05/30/reflections-on-ai-and-the-future-of-human-flourishing/)]. This involves technical approaches to AI safety and alignment as well as broader societal mechanisms for governance. The contrasting philosophies of major AI labs like Anthropic and OpenAI highlight different approaches to this challenge. Maintaining meaningful human control and judgment is paramount. The concept of "hybrid intelligence" emphasizes the synergistic potential of combining human insight, ethical reasoning, and contextual understanding with AI's analytical power [[Walther, C. 2025](https://knowledge.wharton.upenn.edu/article/why-hybrid-intelligence-is-the-future-of-human-ai-collaboration/)]. This requires preserving human oversight, especially in high-stakes or ethically sensitive decisions [[Spitko, E. G. 2024](https://digitalcommons.lib.uconn.edu/cgi/viewcontent.cgi?article=1614&context=law_review)], rather than fully automating judgment.

Shaping AI towards human flourishing requires broader input than technical expertise alone. There is a growing call for the humanities, including fields like philosophy, history, sociology, and the arts, to play a central role not just in analyzing AI's societal impact, but in shaping the fundamental design and goals of AI systems [[Hemment, D. 2025](https://impact.ed.ac.uk/opinion/why-the-humanities-must-shape-the-future-of-ai/)]. This involves fostering greater social and ethical literacy among AI developers and ensuring that diverse cultural perspectives and values inform AI development [[CTF](https://static1.squarespace.com/static/61519ebe46a933184f1a18a3/t/65b26cda3d1d392fba824479/1706192091391/Executive+Summary+New+Perspectives+on+AI+Futures.pdf)]. Sophisticated AI algorithms designed to maximize engagement or influence behavior (e.g., in social media, advertising, political campaigns) raise concerns about manipulation and the erosion of critical thinking, while increased automation and digital interaction could also potentially lead to greater social isolation for some individuals. Learning from the missteps of the social media era, where insufficient attention to content and context led to negative societal consequences like misinformation and polarization, points to the importance of incorporating humanistic perspectives early and deeply in the AI design process [[Hemment, D. 2025](https://impact.ed.ac.uk/opinion/why-the-humanities-must-shape-the-future-of-ai/)].

Ultimately, human flourishing in the age of AI appears intrinsically linked to maintaining agency and enabling meaningful participation. Concerns about the loss of autonomy [[Spitko, E. G. 2024](https://digitalcommons.lib.uconn.edu/cgi/viewcontent.cgi?article=1614&context=law_review)], the need for human judgment [[Walther, C. 2025](https://knowledge.wharton.upenn.edu/article/why-hybrid-intelligence-is-the-future-of-human-ai-collaboration/)], the importance of inclusive design processes [[CTF](https://static1.squarespace.com/static/61519ebe46a933184f1a18a3/t/65b26cda3d1d392fba824479/1706192091391/Executive+Summary+New+Perspectives+on+AI+Futures.pdf)], and the call for humanities to shape AI's foundations [[Hemment, D. 2025](https://impact.ed.ac.uk/opinion/why-the-humanities-must-shape-the-future-of-ai/)] all point towards this conclusion. Flourishing is not merely about receiving the benefits of AI (like increased wealth or efficiency), but about having the capacity to shape the technology, influence its deployment, and ensure it reflects and supports diverse human values and aspirations. This highlights the need for research and policy that focus not only on mitigating risks but also on creating democratic structures and participatory processes that empower individuals and communities in the governance of AI, and study the role of institutional contexts in mediating AI's impact.

The very metrics used to guide AI development and deployment play a critical role. There exists a potential tension between optimizing AI systems solely for narrow economic or technical objectives (e.g., maximizing efficiency, predictive accuracy, user engagement, or corporate profit) and optimizing for broader human well-being. For instance, an AI system designed for maximum workplace efficiency might create a stressful and dehumanizing environment for employees. An algorithm optimized for engagement might promote addictive behavior or spread misinformation, negatively impacting mental health and social trust. Conversely, AI applications explicitly designed to enhance well-being (e.g., mental health chatbots, tools for fostering community connection) might not yield the highest direct economic returns according to traditional metrics. This suggests that the design choices, incentive structures, and governance frameworks surrounding AI development are crucial determinants of its ultimate impact on flourishing. Conscious effort is required to align AI systems with human values and well-being goals, rather than assuming that maximizing economic output will automatically translate into enhanced flourishing. This necessitates moving beyond GDP as the sole measure of progress and developing richer frameworks for evaluating AI's societal impact.

## Towards More Grounded Assessments
The uncertainties and divergent projections surrounding AI's socio-economic impact requires a concerted effort to improve our understanding and develop effective strategies for navigating the coming decades. This means addressing critical research gaps, drawing relevant lessons from history, and engaging in robust policy discussions. Attempting to produce precise, single-point predictions for outcomes spanning decades is likely a futile exercise. Instead, a more productive approach involves mapping the range of plausible futures, understanding the key factors that will shape the trajectory, and identifying robust strategies that can navigate the inherent uncertainty.

### Addressing the Research Deficit: Key Priorities
Synthesizing the critiques of current models and the identified knowledge gaps points towards several key priorities for future research.

#### Granularity in Skill and Task Analysis
Research must move beyond broad occupational categories to understand AI's impact at a finer resolution. This involves precisely mapping how emerging AI capabilities interact with the diverse skill sets required across the economy and analyzing the specific tasks within occupations that are susceptible to automation, augmentation, or transformation. Future models should incorporate greater heterogeneity among workers (skills, adaptability), firms (size, technological capacity, market power), and tasks. They need better representations of endogenous technological change, capturing how innovation responds to incentives and policy. Incorporating firm dynamics (entry, exit, growth, diffusion patterns, drawing on insights from micro-level studies [[Babina, T. et al. 2024](https://www.nber.org/papers/w31325)]) and realistic labor market frictions (search costs, matching inefficiencies, retraining lags and costs, informed by empirical work on adjustments [[Acemoglu, D. et al. 2024](https://shapingwork.mit.edu/wp-content/uploads/2023/10/Paper_Artificial-Intelligence-and-Jobs-Evidence-from-Online-Vacancies.pdf)]) is crucial. 

Significant investment is needed in developing new data infrastructure. This includes collecting granular data on the task content of jobs and how it changes over time, real-time indicators of skill demands (e.g., from online job postings), firm-level adoption and specific use cases of AI technologies, worker transitions (job changes, retraining, wage trajectories), the growth and nature of non-traditional work mediated by AI platforms, and broader metrics of well-being and flourishing beyond GDP. Tracking how AI adoption changes the task composition of jobs over time [[Acemoglu, D. et al. 2024](https://shapingwork.mit.edu/wp-content/uploads/2023/10/Paper_Artificial-Intelligence-and-Jobs-Evidence-from-Online-Vacancies.pdf)], and understanding what are the precise mechanisms and quantitative importance of new task creation spurred by AI and how this process compares to task automation is essential. Evaluation of the effectiveness, cost, scalability, and accessibility of various reskilling and upskilling programs is needed to understand how best to facilitate worker transitions in response to shifting skill demands [[WEF](https://sustainabilitymag.com/articles/wef-report-the-impact-of-ai-driving-170m-new-jobs-by-2030)].

#### Modeling Institutional and Social Contexts
Future models need to integrate the complex web of real-world institutional and social factors that mediate AI's deployment and impact. This includes investigating the role of regulatory frameworks, existing labor laws, the influence of labor unions and worker bargaining power, research and development funding, antitrust and competition policy (especially concerning dominant tech firms), data governance, intellectual property regimes, taxation (e.g., taxing capital/robots vs. labor), social safety nets (e.g., UBI, wage subsidies), and investments in education and lifelong learning [[Korinek, A. et al. 2021](https://www.nber.org/papers/w28453)]. Understanding how social acceptance, public trust, ethical considerations, and cultural attitudes towards technology shape adoption patterns is equally critical [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)]. Research should explicitly model how different institutional environments might lead to divergent outcomes even with similar technological advancements, and study the challenges of policy coordination in this complex landscape [[Makridis, C. A. et al. 2024](https://academic.oup.com/spp/article-abstract/51/3/557/7595834?redirectedFrom=fulltext)].

How firms choose to deploy AI, whether prioritizing cost-cutting automation or value-creating augmentation, will significantly influence labor market outcomes. The speed and breadth of AI diffusion across firms of different sizes and sectors, potentially influenced by factors identified in firm-level studies [[Babina, T. et al. 2024](https://www.nber.org/papers/w31325)], will determine the extent and distribution of productivity gains. The capacity and speed with which workforces adapt through skill acquisition and transitions, the evolution of consumer preferences (e.g., demand for human interaction in services), changes in social norms regarding work, leisure, and income distribution, and the effectiveness of labor market institutions in managing transitions [[Acemoglu, D. et al. 2024](https://shapingwork.mit.edu/wp-content/uploads/2023/10/Paper_Artificial-Intelligence-and-Jobs-Evidence-from-Online-Vacancies.pdf)] are all critical determinants of the socio-economic consequences, and need to be part of future research efforts. Understanding the political economy dynamics of AI adoption and how lobbying, public opinion, and geopolitical competition influence AI policy and its outcomes is also an important direction for future research.  

#### Scenario Analysis
Rather than striving for single-point forecasts, research should focus on developing suites of plausible, integrated scenarios. These scenarios should combine consistent assumptions about technological pathways (informed by technical experts), economic responses, potential policy packages (e.g., laissez-faire vs. proactive intervention), and societal adaptation patterns. Scenario analysis explicitly embraces uncertainty and helps policymakers understand the range of potential outcomes and the sensitivity of those outcomes to key drivers and choices.

#### Understanding Human-AI Collaboration (Hybrid Intelligence)
Given the evidence that augmentation is a significant mode of AI use, research should focus intensively on "human-in-the-loop" systems and hybrid intelligence models [[Walther, C. 2025](https://knowledge.wharton.upenn.edu/article/why-hybrid-intelligence-is-the-future-of-human-ai-collaboration/)]. This involves exploring the implications for optimal job design, evolving workplace structures, wage determination in collaborative settings, and impacts on worker satisfaction, autonomy, and overall well-being [[Spitko, E. G. 2024](https://digitalcommons.lib.uconn.edu/cgi/viewcontent.cgi?article=1614&context=law_review)]. Developing frameworks and best practices for effective human-AI teaming, such as the A-Frame proposed for fostering double literacy [[Walther, C. 2025](https://knowledge.wharton.upenn.edu/article/why-hybrid-intelligence-is-the-future-of-human-ai-collaboration/)], is an important area for applied research.

#### Valuing Non-Market Impacts and Human Flourishing
The research lens must broaden beyond traditional economic metrics like GDP and productivity. Methodologies are needed to quantify the wider economic and social welfare impacts of new tasks and activities enabled by AI, including potential negative externalities (e.g., environmental costs, social fragmentation) [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)]. Assessing AI's effects on the non-economic dimensions of human flourishing, such as job quality, autonomy, equity, social cohesion, sense of purpose, and mental health, requires developing new measurement frameworks and integrating insights from diverse disciplines like sociology, psychology, and ethics. Environmental sustainability implications also warrant greater attention.

#### Methodological Pluralism and Integration
Addressing the complexity of AI's impact requires moving beyond siloed modeling approaches. Future research should strive to integrate insights from different methodologies: combining compute-based models of AI progress (like [Epoch AI's GATE, 2025](https://arxiv.org/abs/2503.04941)) with detailed task-based analyses (like [Acemoglu, D. 2025](https://economics.mit.edu/sites/default/files/2024-04/The%20Simple%20Macroeconomics%20of%20AI.pdf)) and theoretical explorations of long-term possibilities (like [Korinek & Suh 2024](https://www.nber.org/papers/w32255)). Will progress continue its rapid trajectory, potentially leading to AGI or highly capable narrow systems within the forecast horizon? Or will development encounter bottlenecks? Will AI primarily augment human capabilities or substitute for them across a wider range of tasks? The specific technical trajectory matters enormously. Establishing longitudinal studies, perhaps building on initiatives like the Anthropic Economic Index [[Anthropic, 2025](https://www.anthropic.com/news/the-anthropic-economic-index)], is crucial for tracking real-world adoption patterns and impacts dynamically over time. Quantitative modeling should be complemented by qualitative research, in-depth case studies of AI implementation in specific sectors, and historical analysis to provide richer context and understanding. Fostering genuine interdisciplinary collaboration between economists, computer scientists, sociologists, ethicists, and legal scholars is essential for tackling these multifaceted questions [[Hemment, D. 2025](https://impact.ed.ac.uk/opinion/why-the-humanities-must-shape-the-future-of-ai/)].

A crucial element emerging from these priorities is the need for research to be proactive rather than merely reactive. The calls for research to inform ethical design, for humanities to shape AI development, for inclusive design processes, and for longitudinal tracking to understand emerging impacts all point towards a research agenda that aims to actively guide AI's trajectory towards desirable societal outcomes. This involves evaluating potential impacts before technologies become entrenched, developing frameworks for responsible innovation, and exploring governance mechanisms that can shape AI development pathways in alignment with public values. This requires moving beyond purely predictive modeling to incorporate normative analysis and design thinking, fostering closer collaboration between social scientists, humanities scholars, ethicists, policymakers, and AI developers themselves.

### Insights from Technological History
Examining past technological transitions, such as electrification or the widespread adoption of computers, offers valuable context, though direct parallels must be drawn cautiously. History shows that transformative technologies often involve significant periods of disruption, worker displacement, and societal adaptation [[Horvitz, E. 2023](https://blogs.microsoft.com/blog/2023/05/30/reflections-on-ai-and-the-future-of-human-flourishing/)]. Implementation lags, where productivity gains are slow to appear in aggregate statistics despite technological progress, are a recurring phenomenon (the "productivity paradox") [[Brynjolfsson, E. et al. 2019](https://www.nber.org/system/files/working_papers/w24001/w24001.pdf)]. Importantly, historical episodes also suggest that fears of permanent, widespread technological unemployment have often proven unfounded in the long run, as economies eventually adapted, creating new jobs and tasks [[BLS](https://www.bls.gov/opub/mlr/2025/article/incorporating-ai-impacts-in-bls-employment-projections.htm)].

However, AI may possess characteristics that differentiate it from previous general-purpose technologies. The potential speed of AI development and deployment, its broad applicability across both manual and cognitive tasks (including those requiring high skill levels), its capacity for learning and adaptation, and the possibility (however remote or contested) of achieving AGI suggest that the scale and nature of the disruption could be unprecedented [[IMF](https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity)]. Generative AI's specific impact on knowledge work and creative professions represents a novel challenge [[McKinsey](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier)]. Therefore, while history provides reassurance that adaptation is possible and suggests focusing on transition mechanisms, it also cautions against complacency. The unique attributes of AI may necessitate faster, more comprehensive, or qualitatively different policy responses compared to those employed during previous technological shifts.

### Policy Pathways for Shared Prosperity and Well-being
Given the potential for significant disruption and the uncertainty surrounding AI's ultimate impact, proactive policy interventions are crucial for maximizing benefits while mitigating risks and ensuring outcomes align with societal goals. Key policy areas include:

1. **Workforce Adaptation**: Substantial public and private investment in education and training is paramount. This includes robust funding for reskilling and upskilling programs tailored to emerging skill demands, initiatives to promote lifelong learning as a societal norm, and integrating AI literacy across all levels of the education system to prepare future generations [[WEF](https://sustainabilitymag.com/articles/wef-report-the-impact-of-ai-driving-170m-new-jobs-by-2030)].
2.  **Social Safety Nets**: Strengthening social safety nets is essential to support workers and communities negatively affected by AI-driven transitions. This could involve enhancing unemployment benefits, exploring portable benefit systems, or considering more fundamental reforms like UBI or related income support mechanisms to provide economic security amidst labor market volatility [[CBO](https://www.cbo.gov/publication/61147), [Aghion, P. et al. 2017](https://www.nber.org/system/files/working_papers/w23928/w23928.pdf)].
3.  **Labor Market Regulation**: Policies may need adaptation to the changing nature of work. This could involve updating labor laws to address issues arising from algorithmic management (e.g., transparency, fairness, worker data rights) [[Spitko, E. G. 2024](https://digitalcommons.lib.uconn.edu/cgi/viewcontent.cgi?article=1614&context=law_review)], potentially strengthening mechanisms for worker voice and collective bargaining (including emerging AI-focused unions [[Horvitz, E. 2023](https://blogs.microsoft.com/blog/2023/05/30/reflections-on-ai-and-the-future-of-human-flourishing/)]), and establishing frameworks to ensure fair and just transitions for displaced workers.
4. **Competition and Taxation**: Ensuring the economic gains from AI are broadly shared requires attention to market structure and fiscal policy. Antitrust enforcement may be needed to prevent excessive market concentration in AI development and deployment [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)]. Tax policies could be reformed to potentially capture a greater share of returns from AI-driven productivity (e.g., through taxes on capital, corporate profits, or specific AI applications) and redistribute these gains to fund public services or support incomes. Policymakers also need to consider AI's potential impacts on government revenues and expenditures [[CBO](https://www.cbo.gov/publication/61147), [Aghion, P. et al. 2017](https://www.nber.org/system/files/working_papers/w23928/w23928.pdf)].
5. **AI Governance and Ethics**: Establishing clear standards and regulations for AI safety, fairness, transparency, and accountability is critical [[Walther, C. 2025](https://knowledge.wharton.upenn.edu/article/why-hybrid-intelligence-is-the-future-of-human-ai-collaboration/)]. This includes developing mechanisms to audit algorithms for bias, protect user privacy, combat AI-generated misinformation, and ensure human oversight in critical applications [[CEPR](https://cepr.org/voxeu/columns/should-ai-stay-or-should-ai-go-promises-and-perils-ai-productivity-and-growth)]. Given AI's global nature, international cooperation and coordination on AI policy and standards and encouraging public deliberation and participation in shaping AI norms and behaviors is vital [[Makridis, C. A. et al. 2024](https://academic.oup.com/spp/article-abstract/51/3/557/7595834?redirectedFrom=fulltext)].
6. **Investing in AI for Good**: Policy can actively steer AI innovation towards addressing pressing societal challenges, such as improving healthcare diagnostics and treatment, accelerating scientific discovery for climate change mitigation, enhancing education, and promoting sustainable development. Ensuring equitable access to beneficial AI applications globally, particularly in developing economies, should be a key consideration [[CTF](https://static1.squarespace.com/static/61519ebe46a933184f1a18a3/t/65b26cda3d1d392fba824479/1706192091391/Executive+Summary+New+Perspectives+on+AI+Futures.pdf)].
7. **The Role of Adaptive Policy**: Given the deep uncertainty surrounding long-term impacts, policymakers should prioritize building adaptive capacity rather than implementing rigid, long-term plans based on specific forecasts. This involves strengthening social safety nets to cushion inevitable disruptions, investing in robust lifelong learning systems that equip workers with adaptable skills, promoting competition and innovation, closely monitoring AI's impacts across various domains using improved data, and maintaining the flexibility to adjust policies as the technology and its effects evolve. The evidence highlights both immediate transition costs (e.g., layoffs, skill mismatches [[McKinsey, 2023](https://www.mckinsey.com/~/media/mckinsey/mckinsey%20global%20institute/our%20research/generative%20ai%20and%20the%20future%20of%20work%20in%20america/generative-ai-and-the-future-of-work-in-america-vf1.pdf)]) and potential long-term structural shifts towards greater inequality [[IMF](https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity)]. An effective strategy must therefore operate on two levels: providing robust short-term support for individuals and communities navigating disruption (through safety nets, retraining, and active labor market policies) while simultaneously implementing long-term structural policies (related to taxation, competition, labor regulation, and education) designed to shape the distribution of AI's benefits and foster inclusive growth. A piecemeal approach risks being insufficient; a coherent, integrated policy framework, guided by a clear vision for shared prosperity and well-being in the AI era, is essential. Perhaps the most critical analytical task is not to predict the future state precisely, but rather to identify robust policy levers. These are interventions (e.g., investments in foundational skills, progressive tax systems, antitrust enforcement, adaptable social insurance) that are likely to yield positive outcomes, such as promoting shared prosperity, mitigating hardship, and enhancing flourishing, across a wide range of plausible technological and economic scenarios. The research agenda should therefore focus on evaluating the robustness and resilience of different policy options under conditions of deep uncertainty, enabling societies to navigate the AI transition effectively regardless of which specific future unfolds.

## Conclusion
The advent of advanced AI presents humanity with a landscape of possibilities ranging from the profoundly beneficial to the deeply concerning. This review has traversed the spectrum of projections regarding AI's impact on labor, productivity, wages, and human flourishing over the coming decades. The analysis reveals not a clear consensus, but rather a field marked by uncertainty and divergent expert opinions. Forecasts oscillate between visions of an AI-fueled economic renaissance, characterized by explosive productivity growth and enhanced human capabilities, and cautionary tales of widespread job displacement, stagnant wages, and exacerbated social inequalities. The potential exists for AI to augment human work, improve efficiency, and contribute to solving major global challenges; yet, risks related to job quality degradation, algorithmic bias, loss of autonomy, and social fragmentation loom large. Crucially, the trajectory of AI's impact is not technologically predetermined. It will be forged at the complex intersection of ongoing technological innovation, economic incentives, investment decisions, institutional responses, societal adaptation, and deliberate policy choices. The stakes are immense, encompassing not only the future structure of our economies and labor markets but also fundamental aspects of human experience, equity, and well-being.

Navigating this uncertain future demands a renewed commitment to rigorous, nuanced, and forward-looking research. The limitations of current modeling approaches highlight the urgent need for the research priorities outlined in this review: developing more granular analyses of skills and tasks, integrating institutional and social contexts into economic models, deepening our understanding of human-AI collaboration, broadening our valuation metrics to encompass non-market impacts and human flourishing, and embracing methodological pluralism and interdisciplinary collaboration. Research must become more proactive, aiming not just to predict AI's effects but to inform its ethical development and governance.

Alongside enhanced research, the path forward requires a commitment to responsible innovation. This entails embedding ethical considerations and a focus on human well-being into the very design and deployment of AI systems. It necessitates inclusive dialogue involving diverse stakeholders, researchers, developers, policymakers, businesses, workers, and the public, to collectively shape AI's trajectory. We must move beyond simplistic, deterministic views of technology's impact and embrace a more nuanced understanding of AI as a force that co-evolves with our economies, institutions, and values. This requires humility in prediction, coupled with urgency in preparation. Proactive, adaptive, and globally coordinated governance frameworks and robust policy levers capable of steering the AI transition towards desirable outcomes, shared prosperity, enhanced well-being, and broad-based human flourishing, across the wide range of possible futures are needed. The AI revolution is unfolding rapidly; through concerted research, responsible practices, and wise policy, we can strive to harness its immense potential while safeguarding our shared future and fostering a world where technology serves, rather than subverts, human flourishing. The path AI takes is not preordained; it will be shaped by the choices we make today.






















